{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/googlecolab/colabtools/blob/master/notebooks/colab-github-demo.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At the time of our work, we used the following library versions\n",
    "- numpy 1.18.1\n",
    "- pandas 1.0.1\n",
    "- torch 1.2.0\n",
    "- Cuda 10.0\n",
    "- python 3.7.0\n",
    "- sklearn 0.22.1\n",
    "- tqdm 4.42.1\n",
    "- nltk 3.4.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../src/')\n",
    "import collections\n",
    "from typing import Callable\n",
    "import numpy as np\n",
    "np.random.seed(42)\n",
    "import pandas as pd\n",
    "from tqdm import notebook\n",
    "import importlib\n",
    "import pprint\n",
    "import nltk\n",
    "import datetime\n",
    "import os\n",
    "from argparse import Namespace\n",
    "import re\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils.general as general_utils\n",
    "import utils.trac2020 as trac_utils\n",
    "import utils.transformer.data as transformer_data_utils\n",
    "import utils.transformer.general as transformer_general_utils\n",
    "general_utils.set_seed_everywhere() #set the seed for reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.basicConfig(level=logging.INFO) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.1.0'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "torch.__version__\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Optimzer and XLM Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import RAdam and Lookahead\n",
    "from radam.radam import RAdam\n",
    "from lookahead.optimizer import Lookahead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0321 13:53:33.369260 4454915520 file_utils.py:41] PyTorch version 1.1.0 available.\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "from transformers import XLMRobertaTokenizer, XLMRobertaModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up the argspace/important_variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = Namespace(\n",
    "        #use cuda by default\n",
    "        device = 'cuda' if torch.cuda.is_available() else 'cpu',\n",
    "    \n",
    "        #set batch size and number of epochs\n",
    "        batch_size = 32,\n",
    "        num_epochs = 20,\n",
    "    \n",
    "        #set the learning rate\n",
    "        learning_rate = 0.0001,\n",
    "\n",
    "        #location of the train, dev and test csv\n",
    "        train_csv = '../data/hin/trac2_hin_train.csv',\n",
    "        dev_csv = '../data/hin/trac2_hin_dev.csv',\n",
    "        test_csv = '../data/test/trac2_hin_test.csv',\n",
    "    \n",
    "        #directory to save our models at\n",
    "        directory = './' \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data csv into DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['ID', 'Text', 'Sub-task A', 'Sub-task B', 'split'], dtype='object')\n",
      "NAG    2245\n",
      "OAG     910\n",
      "CAG     829\n",
      "Name: Sub-task A, dtype: int64\n",
      "NGEN    3323\n",
      "GEN      661\n",
      "Name: Sub-task B, dtype: int64\n",
      "Size of 'train' split: 3984\n"
     ]
    }
   ],
   "source": [
    "raw_train_df =  pd.read_csv(args.train_csv)\n",
    "raw_train_df['split'] = 'train'\n",
    "print(raw_train_df.columns)\n",
    "print(raw_train_df['Sub-task A'].value_counts())\n",
    "print(raw_train_df['Sub-task B'].value_counts())\n",
    "print(f\"Size of 'train' split: {len(raw_train_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['ID', 'Text', 'Sub-task A', 'Sub-task B', 'split'], dtype='object')\n",
      "NAG    578\n",
      "CAG    211\n",
      "OAG    208\n",
      "Name: Sub-task A, dtype: int64\n",
      "NGEN    845\n",
      "GEN     152\n",
      "Name: Sub-task B, dtype: int64\n",
      "Size of 'dev' split: 997\n"
     ]
    }
   ],
   "source": [
    "raw_dev_df =  pd.read_csv(args.dev_csv)\n",
    "raw_dev_df['split'] = 'dev'\n",
    "print(raw_dev_df.columns)\n",
    "print(raw_dev_df['Sub-task A'].value_counts())\n",
    "print(raw_dev_df['Sub-task B'].value_counts())\n",
    "print(f\"Size of 'dev' split: {len(raw_dev_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Text</th>\n",
       "      <th>Sub-task A</th>\n",
       "      <th>Sub-task B</th>\n",
       "      <th>split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C38.9</td>\n",
       "      <td>bkl interviewers kuch jaada hi open minded bnt...</td>\n",
       "      <td>OAG</td>\n",
       "      <td>NGEN</td>\n",
       "      <td>dev</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C4.1510</td>\n",
       "      <td>Bhaiya shaadi mein zaroor aana movie ka plot j...</td>\n",
       "      <td>NAG</td>\n",
       "      <td>NGEN</td>\n",
       "      <td>dev</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C19.95</td>\n",
       "      <td>Section 375 hai kya??? .... Ye to batate kam s...</td>\n",
       "      <td>NAG</td>\n",
       "      <td>NGEN</td>\n",
       "      <td>dev</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C4.281</td>\n",
       "      <td>कबीर सिंह hit Hui इससे पता चलता है आजकल के लोग...</td>\n",
       "      <td>OAG</td>\n",
       "      <td>NGEN</td>\n",
       "      <td>dev</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C4.216</td>\n",
       "      <td>Maine itni kam dislike kbhi nhii dekhi</td>\n",
       "      <td>NAG</td>\n",
       "      <td>NGEN</td>\n",
       "      <td>dev</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4976</th>\n",
       "      <td>C38.455</td>\n",
       "      <td>Asexual h.. bisexual... homosexual... bhai ase...</td>\n",
       "      <td>NAG</td>\n",
       "      <td>NGEN</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4977</th>\n",
       "      <td>C4.203</td>\n",
       "      <td>Video pura dekne ke pahile hi mai bhai ke vide...</td>\n",
       "      <td>NAG</td>\n",
       "      <td>NGEN</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4978</th>\n",
       "      <td>C45.709</td>\n",
       "      <td>konsa place hai bhai ...nam bolo</td>\n",
       "      <td>NAG</td>\n",
       "      <td>NGEN</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4979</th>\n",
       "      <td>C4.420.1</td>\n",
       "      <td>Kuch zada hi likh diya 🙄</td>\n",
       "      <td>NAG</td>\n",
       "      <td>NGEN</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4980</th>\n",
       "      <td>C7.1913.5</td>\n",
       "      <td>scary tube par kya woh karna sahi tha? Pucha k...</td>\n",
       "      <td>NAG</td>\n",
       "      <td>NGEN</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4981 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             ID                                               Text Sub-task A  \\\n",
       "0         C38.9  bkl interviewers kuch jaada hi open minded bnt...        OAG   \n",
       "1       C4.1510  Bhaiya shaadi mein zaroor aana movie ka plot j...        NAG   \n",
       "2        C19.95  Section 375 hai kya??? .... Ye to batate kam s...        NAG   \n",
       "3        C4.281  कबीर सिंह hit Hui इससे पता चलता है आजकल के लोग...        OAG   \n",
       "4        C4.216             Maine itni kam dislike kbhi nhii dekhi        NAG   \n",
       "...         ...                                                ...        ...   \n",
       "4976    C38.455  Asexual h.. bisexual... homosexual... bhai ase...        NAG   \n",
       "4977     C4.203  Video pura dekne ke pahile hi mai bhai ke vide...        NAG   \n",
       "4978    C45.709                   konsa place hai bhai ...nam bolo        NAG   \n",
       "4979   C4.420.1                           Kuch zada hi likh diya 🙄        NAG   \n",
       "4980  C7.1913.5  scary tube par kya woh karna sahi tha? Pucha k...        NAG   \n",
       "\n",
       "     Sub-task B  split  \n",
       "0          NGEN    dev  \n",
       "1          NGEN    dev  \n",
       "2          NGEN    dev  \n",
       "3          NGEN    dev  \n",
       "4          NGEN    dev  \n",
       "...         ...    ...  \n",
       "4976       NGEN  train  \n",
       "4977       NGEN  train  \n",
       "4978       NGEN  train  \n",
       "4979       NGEN  train  \n",
       "4980       NGEN  train  \n",
       "\n",
       "[4981 rows x 5 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Concatinate both train and dev dfs together\n",
    "data_df = pd.concat([raw_dev_df, raw_train_df], ignore_index= True)\n",
    "data_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Samples given per label size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total dev + train size = 4981\n",
      "\n",
      "NAG    2823\n",
      "OAG    1118\n",
      "CAG    1040\n",
      "Name: Sub-task A, dtype: int64 \n",
      "\n",
      "NGEN    4168\n",
      "GEN      813\n",
      "Name: Sub-task B, dtype: int64 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f'Total dev + train size = {len(data_df)}\\n')\n",
    "print(data_df['Sub-task A'].value_counts(),'\\n')\n",
    "print(data_df['Sub-task B'].value_counts(),'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Map to labels to integer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'NGEN': 0, 'GEN': 1}\n"
     ]
    }
   ],
   "source": [
    "task_b_label_dict = {'NGEN':0, 'GEN':1}\n",
    "print(task_b_label_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Renaming the columns for our torch dataset class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C38.9</td>\n",
       "      <td>bkl interviewers kuch jaada hi open minded bnt...</td>\n",
       "      <td>0</td>\n",
       "      <td>dev</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C4.1510</td>\n",
       "      <td>Bhaiya shaadi mein zaroor aana movie ka plot j...</td>\n",
       "      <td>0</td>\n",
       "      <td>dev</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C19.95</td>\n",
       "      <td>Section 375 hai kya??? .... Ye to batate kam s...</td>\n",
       "      <td>0</td>\n",
       "      <td>dev</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C4.281</td>\n",
       "      <td>कबीर सिंह hit Hui इससे पता चलता है आजकल के लोग...</td>\n",
       "      <td>0</td>\n",
       "      <td>dev</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C4.216</td>\n",
       "      <td>Maine itni kam dislike kbhi nhii dekhi</td>\n",
       "      <td>0</td>\n",
       "      <td>dev</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4976</th>\n",
       "      <td>C38.455</td>\n",
       "      <td>Asexual h.. bisexual... homosexual... bhai ase...</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4977</th>\n",
       "      <td>C4.203</td>\n",
       "      <td>Video pura dekne ke pahile hi mai bhai ke vide...</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4978</th>\n",
       "      <td>C45.709</td>\n",
       "      <td>konsa place hai bhai ...nam bolo</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4979</th>\n",
       "      <td>C4.420.1</td>\n",
       "      <td>Kuch zada hi likh diya 🙄</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4980</th>\n",
       "      <td>C7.1913.5</td>\n",
       "      <td>scary tube par kya woh karna sahi tha? Pucha k...</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4981 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             ID                                               text  label  \\\n",
       "0         C38.9  bkl interviewers kuch jaada hi open minded bnt...      0   \n",
       "1       C4.1510  Bhaiya shaadi mein zaroor aana movie ka plot j...      0   \n",
       "2        C19.95  Section 375 hai kya??? .... Ye to batate kam s...      0   \n",
       "3        C4.281  कबीर सिंह hit Hui इससे पता चलता है आजकल के लोग...      0   \n",
       "4        C4.216             Maine itni kam dislike kbhi nhii dekhi      0   \n",
       "...         ...                                                ...    ...   \n",
       "4976    C38.455  Asexual h.. bisexual... homosexual... bhai ase...      0   \n",
       "4977     C4.203  Video pura dekne ke pahile hi mai bhai ke vide...      0   \n",
       "4978    C45.709                   konsa place hai bhai ...nam bolo      0   \n",
       "4979   C4.420.1                           Kuch zada hi likh diya 🙄      0   \n",
       "4980  C7.1913.5  scary tube par kya woh karna sahi tha? Pucha k...      0   \n",
       "\n",
       "      split  \n",
       "0       dev  \n",
       "1       dev  \n",
       "2       dev  \n",
       "3       dev  \n",
       "4       dev  \n",
       "...     ...  \n",
       "4976  train  \n",
       "4977  train  \n",
       "4978  train  \n",
       "4979  train  \n",
       "4980  train  \n",
       "\n",
       "[4981 rows x 4 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df_task_b = data_df[['ID','Text','Sub-task B','split']].copy()\n",
    "data_df_task_b.columns.values[1] = 'text'\n",
    "data_df_task_b.columns.values[2] = 'label'\n",
    "data_df_task_b.loc[:,'label'] = data_df_task_b.loc[:,'label'].map(task_b_label_dict) \n",
    "data_df_task_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num samples per class\n",
      "0    4168\n",
      "1     813\n",
      "Name: label, dtype: int64\n",
      "\n",
      "Num samples per split\n",
      "train    3984\n",
      "dev       997\n",
      "Name: split, dtype: int64\n",
      "\n",
      "Label counts in dev split\n",
      "0    845\n",
      "1    152\n",
      "Name: label, dtype: int64\n",
      "\n",
      "Label counts in train split\n",
      "0    3323\n",
      "1     661\n",
      "Name: label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"Num samples per class\")\n",
    "print(data_df_task_b.label.value_counts())\n",
    "\n",
    "print(\"\\nNum samples per split\")\n",
    "print(data_df_task_b.split.value_counts())\n",
    "\n",
    "print(\"\\nLabel counts in dev split\")\n",
    "print(data_df_task_b[data_df_task_b.split=='dev'].label.value_counts())\n",
    "\n",
    "print(\"\\nLabel counts in train split\")\n",
    "print(data_df_task_b[data_df_task_b.split=='train'].label.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We split long samples into multiple samples\n",
    "Each sample produced from from a single split will have the label of the original sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split long sentences into sentences of 200 words\n",
    "data_df_task_b['text'] = data_df_task_b['text'].map(lambda x: trac_utils.chunk_sent(x,150,50))\n",
    "exploded_df = data_df_task_b.explode('text').reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Notice how a single sample is split into two samples in the exploded_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1706</th>\n",
       "      <td>C7.849</td>\n",
       "      <td>[**प्रशासक समिति✊🚩** 😡😡😡😡😡😡😡😡😡 **आर्यो को आंतक...</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          ID                                               text  label  split\n",
       "1706  C7.849  [**प्रशासक समिति✊🚩** 😡😡😡😡😡😡😡😡😡 **आर्यो को आंतक...      0  train"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df_task_b[data_df_task_b.ID=='C7.849']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>ID</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1712</th>\n",
       "      <td>1706</td>\n",
       "      <td>C7.849</td>\n",
       "      <td>**प्रशासक समिति✊🚩** 😡😡😡😡😡😡😡😡😡 **आर्यो को आंतकी...</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1713</th>\n",
       "      <td>1706</td>\n",
       "      <td>C7.849</td>\n",
       "      <td>कर उन्हें दूर भी किया और अब भी कोशिश चालू है, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      index      ID                                               text  label  \\\n",
       "1712   1706  C7.849  **प्रशासक समिति✊🚩** 😡😡😡😡😡😡😡😡😡 **आर्यो को आंतकी...      0   \n",
       "1713   1706  C7.849  कर उन्हें दूर भी किया और अब भी कोशिश चालू है, ...      0   \n",
       "\n",
       "      split  \n",
       "1712  train  \n",
       "1713  train  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exploded_df[exploded_df.ID == 'C7.849']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples before splitting\n",
      "train    3984\n",
      "dev       997\n",
      "Name: split, dtype: int64\n",
      "\n",
      "Samples After splitting\n",
      "train    4006\n",
      "dev       999\n",
      "Name: split, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"Samples before splitting\")\n",
    "print(data_df_task_b.split.value_counts())\n",
    "\n",
    "print(\"\\nSamples After splitting\")\n",
    "print(exploded_df.split.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the text preprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RobertaPreprocessor():\n",
    "    \"\"\"\n",
    "    Preprocessor for adding special tokens into each sample\n",
    "    NOTE: Doesn't work perfectly.\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    def __init__(self,transformer_tokenizer,sentence_detector):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            transformer_tokenizer: Tokenizer for the transformer model\n",
    "            sentence_detector: Sentence tokenizer.\n",
    "        \"\"\"\n",
    "        self.transformer_tokenizer = transformer_tokenizer\n",
    "        self.sentence_detector = sentence_detector\n",
    "        self.bos_token = transformer_tokenizer.bos_token\n",
    "        self.sep_token = ' ' + transformer_tokenizer.sep_token + ' '\n",
    "        \n",
    "    def add_special_tokens(self, text):\n",
    "        \"\"\"\n",
    "        Adds '</s>' between each sentence and at the end of the sample.\n",
    "        Adds '<s>' at the start of the sentence.\n",
    "        \n",
    "        Args:\n",
    "            text: Text sample to add special tokens into\n",
    "        Returns:\n",
    "            text with special tokens added\n",
    "        \"\"\"\n",
    "        text = ' '.join(text.strip().split()) #clean whitespaces\n",
    "        sentences = self.sentence_detector.tokenize(text)\n",
    "        eos_added_text  = self.sep_token.join(sentences) \n",
    "        return self.bos_token +' '+ eos_added_text + ' ' + self.transformer_tokenizer.sep_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0321 13:54:18.007902 4454915520 filelock.py:274] Lock 5198573240 acquired on /Users/cozek/.cache/torch/transformers/0c370616ddfc06067c0634160f749c2cf9d8da2c50e03a2617ce5841c8df3b1d.309f0c29486cffc28e1e40a2ab0ac8f500c203fe080b95f820aa9cb58e5b84ed.lock\n",
      "I0321 13:54:18.013113 4454915520 file_utils.py:460] https://s3.amazonaws.com/models.huggingface.co/bert/xlm-roberta-base-sentencepiece.bpe.model not found in cache or force_download set to True, downloading to /Users/cozek/.cache/torch/transformers/tmpyojh5kf8\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ba5ffc3c5c143808cd059433327016f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=5069051.0, style=ProgressStyle(descript…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0321 13:55:51.341168 4454915520 file_utils.py:470] storing https://s3.amazonaws.com/models.huggingface.co/bert/xlm-roberta-base-sentencepiece.bpe.model in cache at /Users/cozek/.cache/torch/transformers/0c370616ddfc06067c0634160f749c2cf9d8da2c50e03a2617ce5841c8df3b1d.309f0c29486cffc28e1e40a2ab0ac8f500c203fe080b95f820aa9cb58e5b84ed\n",
      "I0321 13:55:51.343251 4454915520 file_utils.py:473] creating metadata file for /Users/cozek/.cache/torch/transformers/0c370616ddfc06067c0634160f749c2cf9d8da2c50e03a2617ce5841c8df3b1d.309f0c29486cffc28e1e40a2ab0ac8f500c203fe080b95f820aa9cb58e5b84ed\n",
      "I0321 13:55:51.345571 4454915520 filelock.py:318] Lock 5198573240 released on /Users/cozek/.cache/torch/transformers/0c370616ddfc06067c0634160f749c2cf9d8da2c50e03a2617ce5841c8df3b1d.309f0c29486cffc28e1e40a2ab0ac8f500c203fe080b95f820aa9cb58e5b84ed.lock\n",
      "I0321 13:55:51.346597 4454915520 tokenization_utils.py:484] loading file https://s3.amazonaws.com/models.huggingface.co/bert/xlm-roberta-base-sentencepiece.bpe.model from cache at /Users/cozek/.cache/torch/transformers/0c370616ddfc06067c0634160f749c2cf9d8da2c50e03a2617ce5841c8df3b1d.309f0c29486cffc28e1e40a2ab0ac8f500c203fe080b95f820aa9cb58e5b84ed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "xlmroberta_tokenizer = XLMRobertaTokenizer.from_pretrained('xlm-roberta-base')\n",
    "punkt_sentence_detector = nltk.data.load('tokenizers/punkt/english.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "roberta_preproc = RobertaPreprocessor(xlmroberta_tokenizer, punkt_sentence_detector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#apply the preprocessor on the exploded dataframe\n",
    "exploded_df['text'] = exploded_df['text'].map(roberta_preproc.add_special_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<s> Section 375 hai kya??? </s> .... Ye to batate kam se kam </s>'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exploded_df.loc[2].text #notice the addition of eos token"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the Vectorizer and the torch Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleVectorizer():\n",
    "    \"\"\"Vectorizes Class to encode the samples into \n",
    "    their token ids and creates their respective attention masks\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self,tokenizer: Callable, max_seq_len: int):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            tokenizer (Callable): transformer tokenizer\n",
    "            max_seq_len (int): Maximum sequence lenght \n",
    "        \"\"\"\n",
    "        self.tokenizer = tokenizer\n",
    "        self._max_seq_len = max_seq_len\n",
    "\n",
    "    def vectorize(self,text :str):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            text: Text sample to vectorize\n",
    "        Returns:\n",
    "            ids: Token ids of the \n",
    "            attn: Attention masks for ids \n",
    "        \"\"\"\n",
    "        encoded = self.tokenizer.encode_plus(\n",
    "            text,\n",
    "            add_special_tokens=False, #already added by preprocessor\n",
    "            max_length = self._max_seq_len,\n",
    "            pad_to_max_length = True,\n",
    "        )\n",
    "        ids =  np.array(encoded['input_ids'], dtype=np.int64)\n",
    "        attn = np.array(encoded['attention_mask'], dtype=np.int64)\n",
    "        \n",
    "        return ids, attn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TracDataset(Dataset):\n",
    "    \"\"\"PyTorch dataset class\"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        data_df: pd.DataFrame,\n",
    "        tokenizer: Callable,\n",
    "        max_seq_length:int = None,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            data_df (pandas.DataFrame): df containing the labels and text\n",
    "            tokenizer (Callable): tokenizer for the transformer\n",
    "            max_seq_length (int): Maximum sequece length to work with.\n",
    "        \"\"\"\n",
    "        self.data_df = data_df\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "        if max_seq_length is None:\n",
    "            self._max_seq_length = self._get_max_len(data_df,tokenizer)\n",
    "        else:\n",
    "            self._max_seq_length = max_seq_length\n",
    "\n",
    "        self.train_df = self.data_df[self.data_df.split == 'train']\n",
    "        self.train_size = len(self.train_df)\n",
    "\n",
    "        self.val_df = self.data_df[self.data_df.split == 'dev']\n",
    "        self.val_size = len(self.val_df)\n",
    "\n",
    "        self.test_df = self.data_df[self.data_df.split == 'test']\n",
    "        self.test_size = len(self.test_df)\n",
    "        \n",
    "        self._simple_vectorizer = SimpleVectorizer(tokenizer, self._max_seq_length)\n",
    "        \n",
    "        self._lookup_dict = {\n",
    "            'train': (self.train_df, self.train_size),\n",
    "            'val': (self.val_df, self.val_size),\n",
    "            'test': (self.test_df, self.test_size)\n",
    "        }\n",
    "\n",
    "        self.set_split('train')\n",
    "\n",
    "    \n",
    "    def _get_max_len(self,data_df: pd.DataFrame, tokenizer: Callable):\n",
    "        \"\"\"Get the maximum lenght found in the data\n",
    "        Args:\n",
    "            data_df (pandas.DataFrame): The pandas dataframe with the data\n",
    "            tokenizer (Callable): The tokenizer of the transformer\n",
    "        Returns:\n",
    "            max_len (int): Maximum length\n",
    "        \"\"\"\n",
    "        len_func = lambda x: len(self.tokenizer.encode_plus(x)['input_ids'])\n",
    "        max_len = data_df.text.map(len_func).max() \n",
    "        return max_len\n",
    "\n",
    "    \n",
    "    def set_split(self, split=\"train\"):\n",
    "        \"\"\"selects the splits in the dataset using a column in the dataframe \"\"\"\n",
    "        self._target_split = split\n",
    "        self._target_df, self._target_size = self._lookup_dict[split]\n",
    "    \n",
    "    \n",
    "    def __len__(self):\n",
    "        return self._target_size\n",
    "    \n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"the primary entry point method for PyTorch datasets\n",
    "        \n",
    "        Args:\n",
    "            index (int): the index to the data point \n",
    "        Returns:\n",
    "            a dictionary holding the data point's features (x_data) and label (y_target)\n",
    "        \"\"\"\n",
    "        row = self._target_df.iloc[index]\n",
    "\n",
    "        \n",
    "        indices, attention_masks = self._simple_vectorizer.vectorize(row.text)\n",
    "\n",
    "\n",
    "        label = row.label\n",
    "        return {'x_data': indices,\n",
    "                'x_attn_mask': attention_masks,\n",
    "                'x_index': index,\n",
    "                'y_target': label}\n",
    "    \n",
    "    \n",
    "    def get_num_batches(self, batch_size):\n",
    "        \"\"\"Given a batch size, return the number of batches in the dataset\n",
    "        \n",
    "        Args:\n",
    "            batch_size (int)\n",
    "        Returns:\n",
    "            number of batches in the dataset\n",
    "        \"\"\"\n",
    "        return len(self) // batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_batches(dataset, batch_size, shuffle=True,\n",
    "                     drop_last=False, device=\"cpu\", pinned_memory = False, n_workers = 0): \n",
    "    \"\"\"\n",
    "    A generator function which wraps the PyTorch DataLoader. It will \n",
    "      ensure each tensor is on the write device location.\n",
    "    \"\"\"\n",
    "    dataloader = DataLoader(dataset=dataset, batch_size=batch_size,\n",
    "                            shuffle=shuffle, drop_last=drop_last,\n",
    "                            pin_memory= pinned_memory,\n",
    "                            num_workers = n_workers,\n",
    "                            )\n",
    "    \n",
    "    for data_dict in dataloader:\n",
    "        out_data_dict = {}\n",
    "        out_data_dict['x_data'] = data_dict['x_data'].to(\n",
    "            device, non_blocking= (True if pinned_memory else False) \n",
    "        )\n",
    "        out_data_dict['x_attn_mask'] = data_dict['x_attn_mask'].to(\n",
    "            device, non_blocking= (True if pinned_memory else False) \n",
    "        )\n",
    "        out_data_dict['x_index'] = data_dict['x_index']\n",
    "        out_data_dict['y_target'] = data_dict['y_target'].to(\n",
    "            device, non_blocking= (True if pinned_memory else False) \n",
    "        )\n",
    "        yield out_data_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'TracDataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-f3ae75f76cd3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m dataset = TracDataset(\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mdata_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexploded_df\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxlmroberta_tokenizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mmax_seq_length\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m403\u001b[0m \u001b[0;31m#what we used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m )\n",
      "\u001b[0;31mNameError\u001b[0m: name 'TracDataset' is not defined"
     ]
    }
   ],
   "source": [
    "dataset = TracDataset(\n",
    "    data_df = exploded_df,\n",
    "    tokenizer = xlmroberta_tokenizer,\n",
    "    max_seq_length = 403 #what we used\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "365"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset._max_seq_length # make sure its safe enough for our model, i,e, < 512"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating the XLMRoberta + Attention model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class XLMRoBertAttention(nn.Module):\n",
    "    \"\"\"Implements Attention Head Classifier\n",
    "    on Pretrained Roberta Transformer representations.\n",
    "    Attention Head Implementation based on: https://www.aclweb.org/anthology/P16-2034/\n",
    "    \"\"\"\n",
    "    \n",
    "    def penalized_tanh(self,x):\n",
    "        \"\"\"\n",
    "        http://aclweb.org/anthology/D18-1472\n",
    "        \"\"\"\n",
    "        alpha = 0.25\n",
    "        return torch.max(torch.tanh(x), alpha*torch.tanh(x))\n",
    "    \n",
    "    \n",
    "    def __init__(self, model_name, num_labels):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            model_name: model name, eg, roberta-base'\n",
    "            num_labels: number of classes to classify\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.w = nn.Linear(768,1, bias=False)\n",
    "        self.bert = XLMRobertaModel.from_pretrained(model_name)\n",
    "        self.prediction_layer = nn.Linear(768, num_labels)\n",
    "        self.init_weights()\n",
    "        \n",
    "        \n",
    "    def init_weights(self):\n",
    "        \"\"\"Initializes the weights of the Attention head classifier\"\"\"\n",
    "        \n",
    "        for name, param in self.prediction_layer.named_parameters():\n",
    "            if 'bias' in name:\n",
    "                nn.init.constant_(param, 0.0)\n",
    "            elif 'weight' in name:\n",
    "                nn.init.xavier_uniform_(param)\n",
    "        for name, param in self.w.named_parameters():\n",
    "            if 'bias' in name:\n",
    "                nn.init.constant_(param, 0.0)\n",
    "            elif 'weight' in name:\n",
    "                nn.init.xavier_uniform_(param)\n",
    "        \n",
    "        \n",
    "    def forward(self, input_ids,attention_mask):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            input_ids: sent encoded into indices\n",
    "            attention_mask: their respective attention masks\n",
    "        Returns:\n",
    "            preds: Final layer output of the model\n",
    "        \"\"\"\n",
    "        embeddings = self.bert(input_ids = input_ids,\n",
    "                  attention_mask = attention_mask)\n",
    "        H = embeddings[0] #final hidden layer outputs \n",
    "        M = self.penalized_tanh(H)\n",
    "        alpha = torch.softmax(self.w(M), dim=1)\n",
    "        r = torch.bmm(H.permute(0,2,1),alpha)\n",
    "        h_star = self.penalized_tanh(r)\n",
    "        preds = self.prediction_layer(h_star.permute(0,2,1))\n",
    "        return preds\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initializing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:transformers.configuration_utils:loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/xlm-roberta-base-config.json from cache at /home/kaushik.das/.cache/torch/transformers/762ddd751172e9d3229e5da17a459eee6c0dfdc237c718944d0b1a85f06c7e1e.9ba214636e460976b286b4ce15e95d778f32439e9fdd8ddae7e3784f3a7e24a2\n",
      "INFO:transformers.configuration_utils:Model config XLMRobertaConfig {\n",
      "  \"architectures\": [\n",
      "    \"XLMRobertaForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": null,\n",
      "  \"do_sample\": false,\n",
      "  \"eos_token_ids\": null,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"length_penalty\": 1.0,\n",
      "  \"max_length\": 20,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"xlm-roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_beams\": 1,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"num_return_sequences\": 1,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": null,\n",
      "  \"pruned_heads\": {},\n",
      "  \"repetition_penalty\": 1.0,\n",
      "  \"temperature\": 1.0,\n",
      "  \"top_k\": 50,\n",
      "  \"top_p\": 1.0,\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 250002\n",
      "}\n",
      "\n",
      "INFO:transformers.modeling_utils:loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/xlm-roberta-base-pytorch_model.bin from cache at /home/kaushik.das/.cache/torch/transformers/f80a708b21cc9b248e8af5a630ad9f887326bbaf0098b9f354427b2463d55346.aeeaca90954dc20ffa2909de722cfbfd455c5bb16d480c5bdf6d7fe79c68c267\n"
     ]
    }
   ],
   "source": [
    "model = XLMRoBertAttention(\n",
    "    model_name = 'xlm-roberta-base',\n",
    "    num_labels = len(set(dataset.data_df.label)),\n",
    ")\n",
    "model.to(args.device) #send the model to the 'cpu' or 'gpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using LR:0.0001\n"
     ]
    }
   ],
   "source": [
    "loss_func = nn.CrossEntropyLoss()\n",
    "early_stopping = transformer_general_utils.EarlyStopping(patience=4)\n",
    "base_optimizer = RAdam(model.parameters(), lr = args.learning_rate, weight_decay=1e-5)\n",
    "optimizer = Lookahead(optimizer = base_optimizer, k = 6, alpha=0.5 )\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer=optimizer.optimizer, factor =0.1 ,mode='max')\n",
    "\n",
    "print(f'Using LR:{args.learning_rate}\\n Early Stopping Patience: 4')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Begin Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['train_preds', 'train_indexes', 'train_targets', 'train_accuracies', 'train_f1s', 'train_losses', 'val_preds', 'val_indexes', 'val_targets', 'val_accuracies', 'val_f1s', 'val_losses', 'test_preds', 'test_indexes', 'test_targets', 'test_accuracies', 'test_f1s', 'test_losses', 'batch_preds', 'batch_targets', 'batch_indexes', 'epoch_index'])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_state = general_utils.make_train_state() #dictionary for saving training routine information\n",
    "train_state.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12545a96e60d4373b7056cbf4f6fb9df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='training_routine', max=20.0, style=ProgressStyle(descript…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c82d7025ac7f4730a24fdb4ed1acd49f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='split=train ', max=125.0, style=ProgressStyle(description…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03b51c27859f4b6895a126371463c8d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='split=eval', max=31.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping counter: 1 out of 4\n",
      "EarlyStopping counter: 2 out of 4\n",
      "EarlyStopping counter: 3 out of 4\n",
      "EarlyStopping counter: 4 out of 4\n",
      "Early stopping\n"
     ]
    }
   ],
   "source": [
    "epoch_bar = notebook.tqdm(\n",
    "    desc = 'training_routine',\n",
    "    total = args.num_epochs,\n",
    "    position=0,\n",
    "    leave = True,\n",
    ")\n",
    "dataset.set_split('train')\n",
    "train_bar = notebook.tqdm(\n",
    "    desc = 'split=train ',\n",
    "    total=dataset.get_num_batches(args.batch_size),\n",
    "    position=0,\n",
    "    leave=True,\n",
    ")\n",
    "dataset.set_split('val')\n",
    "eval_bar = notebook.tqdm(\n",
    "    desc = 'split=eval',\n",
    "    total=dataset.get_num_batches(args.batch_size),\n",
    "    position=0,\n",
    "    leave=True,\n",
    ")\n",
    "\n",
    "for epoch_index in range(args.num_epochs):\n",
    "    train_state['epoch_in'] = epoch_index\n",
    "\n",
    "    dataset.set_split('train')\n",
    "    batch_generator = generate_batches(\n",
    "        dataset= dataset, batch_size= args.batch_size, shuffle=True,\n",
    "        device = args.device, drop_last=False,\n",
    "        pinned_memory = True, n_workers = 3, \n",
    "    )\n",
    "\n",
    "    running_loss = 0.0\n",
    "    running_acc = 0.0\n",
    "    running_f1 = 0.0\n",
    "    model.train()\n",
    "\n",
    "    train_bar.reset(\n",
    "        total=dataset.get_num_batches(args.batch_size),\n",
    "    )\n",
    "    model.train()\n",
    "    for batch_index, batch_dict in enumerate(batch_generator):\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        y_pred = model(\n",
    "            input_ids = batch_dict['x_data'],\n",
    "            attention_mask =  batch_dict['x_attn_mask'],\n",
    "        )\n",
    "        y_pred = y_pred.view(-1, len(set(dataset.data_df.label)))\n",
    "                             \n",
    "        loss = loss_func(y_pred, batch_dict['y_target'])\n",
    "    \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "                             \n",
    "        loss_t = loss.item()\n",
    "        running_loss += (loss_t - running_loss) / (batch_index + 1)\n",
    "                             \n",
    "        y_pred = y_pred.detach().cpu()\n",
    "        batch_dict['y_target'] = batch_dict['y_target'].cpu()\n",
    "        \n",
    "        acc_t = transformer_general_utils \\\n",
    "            .compute_accuracy(y_pred, batch_dict['y_target'])\n",
    "        atom\n",
    "        f1_t = transformer_general_utils \\\n",
    "            .compute_macro_f1(y_pred, batch_dict['y_target'], average='weighted')\n",
    "\n",
    "        train_state['batch_preds'].append(y_pred)\n",
    "        train_state['batch_targets'].append(batch_dict['y_target'])\n",
    "        train_state['batch_indexes'].append(batch_dict['x_index'])\n",
    "\n",
    "        running_acc += (acc_t - running_acc) / (batch_index + 1)\n",
    "        running_f1 += (f1_t - running_f1) / (batch_index + 1)\n",
    "\n",
    "        train_bar.set_postfix(loss = running_loss, f1 = running_f1, acc=running_acc,\n",
    "                             epoch=epoch_index)\n",
    "\n",
    "        train_bar.update()\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()\n",
    "    \n",
    "    train_state['train_accuracies'].append(running_acc)\n",
    "    train_state['train_losses'].append(running_loss)\n",
    "    \n",
    "    train_state['train_preds'].append(\n",
    "        torch.cat(train_state['batch_preds']).cpu()\n",
    "    )\n",
    "    train_state['train_targets'].append(\n",
    "        torch.cat(train_state['batch_targets']).cpu()\n",
    "    )\n",
    "    train_state['train_indexes'].append(\n",
    "        torch.cat(train_state['batch_indexes']).cpu()\n",
    "    )\n",
    "    train_f1 = transformer_general_utils \\\n",
    "                .compute_macro_f1(train_state['train_preds'][-1],\n",
    "                                  train_state['train_targets'][-1],\n",
    "                                  'weighted'\n",
    "                                 )\n",
    "                                 \n",
    "    train_state['train_f1s'].append(train_f1)\n",
    "    \n",
    "    train_state['batch_preds'] = []\n",
    "    train_state['batch_targets'] = []\n",
    "    train_state['batch_indexes'] = []\n",
    "    \n",
    "    \n",
    "    dataset.set_split('val')\n",
    "    batch_generator = generate_batches(\n",
    "        dataset= dataset, batch_size= args.batch_size, shuffle=True,\n",
    "        device = args.device, drop_last=False,\n",
    "        pinned_memory = False, n_workers = 2, \n",
    "    )\n",
    "    eval_bar.reset(\n",
    "        total=dataset.get_num_batches(args.batch_size),\n",
    "    )\n",
    "    running_loss = 0.0\n",
    "    running_acc = 0.0\n",
    "    running_f1 = 0.0\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        optimizer._backup_and_load_cache()\n",
    "        for batch_index, batch_dict in enumerate(batch_generator):\n",
    "            y_pred = model(\n",
    "                input_ids = batch_dict['x_data'],\n",
    "                attention_mask =  batch_dict['x_attn_mask'],\n",
    "            )\n",
    "            y_pred = y_pred.view(-1, len(set(dataset.data_df.label)))\n",
    "\n",
    "            loss = loss_func(y_pred, batch_dict['y_target'])\n",
    "            running_loss += (loss_t - running_loss) / (batch_index + 1)\n",
    "\n",
    "            y_pred = y_pred.detach()\n",
    "            \n",
    "            acc_t = transformer_general_utils\\\n",
    "                .compute_accuracy(y_pred, batch_dict['y_target'])\n",
    "            f1_t = transformer_general_utils \\\n",
    "                .compute_macro_f1(y_pred, batch_dict['y_target'],\n",
    "                                 average='weighted')\n",
    "\n",
    "            train_state['batch_preds'].append(y_pred.cpu())\n",
    "            train_state['batch_targets'].append(batch_dict['y_target'])\n",
    "            train_state['batch_indexes'].append(batch_dict['x_index'].cpu())\n",
    "\n",
    "            running_acc += (acc_t - running_acc) / (batch_index + 1)\n",
    "            running_f1 += (f1_t - running_f1) / (batch_index + 1)\n",
    "            \n",
    "\n",
    "            eval_bar.set_postfix(loss = running_loss, f1 = running_f1, acc=running_acc,\n",
    "                                 epoch=epoch_index)\n",
    "            eval_bar.update()\n",
    "            \n",
    "    train_state['val_accuracies'].append(running_acc)\n",
    "    train_state['val_losses'].append(running_loss)\n",
    "    \n",
    "        \n",
    "    train_state['val_preds'].append(\n",
    "        torch.cat(train_state['batch_preds']).cpu()\n",
    "    )\n",
    "\n",
    "    train_state['val_targets'].append(\n",
    "        torch.cat(train_state['batch_targets']).cpu()\n",
    "    )\n",
    "    train_state['val_indexes'].append(\n",
    "        torch.cat(train_state['batch_indexes']).cpu()\n",
    "    )\n",
    "    val_f1 = transformer_general_utils \\\n",
    "                .compute_macro_f1(train_state['val_preds'][-1],\n",
    "                                  train_state['val_targets'][-1],\n",
    "                                  average='weighted',\n",
    "                                 )\n",
    "                                 \n",
    "    train_state['val_f1s'].append(val_f1)\n",
    "    \n",
    "    train_state['batch_preds'] = []\n",
    "    train_state['batch_targets'] = []\n",
    "    train_state['batch_indexes'] = []\n",
    "    \n",
    "    torch.save(\n",
    "        {\n",
    "            'model':model.state_dict(),\n",
    "        },\n",
    "        args.directory + f'_epoc_{epoch_index}_' + args.model_name,\n",
    "    )\n",
    "    \n",
    "    scheduler.step(val_f1)\n",
    "    early_stopping(val_f1, model)\n",
    "    optimizer._clear_and_load_backup()\n",
    "    epoch_bar.set_postfix( best_f1 = early_stopping.best_score, current = val_f1)\n",
    "    epoch_bar.update()    \n",
    "    \n",
    "    if early_stopping.early_stop:\n",
    "            print(\"Early stopping\")\n",
    "            break\n",
    "    epoch_bar.set_postfix( best_f1 = early_stopping.best_score, current = val_f1 )\n",
    "    epoch_bar.update()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.7556380769461755, 0.7782906714806137, 0.8591663457360611, 0.8934117790110065, 0.9192519291763898, 0.9378599232099268, 0.947936706951426, 0.9640521740272423]\n"
     ]
    }
   ],
   "source": [
    "print(train_state['train_f1s'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.7766205229619864, 0.8162086486974713, 0.8892706455609094, 0.89078298750255, 0.8827026262600857, 0.8755408456365394, 0.8892586948691369, 0.8812245500770091]\n"
     ]
    }
   ],
   "source": [
    "print(train_state['val_f1s'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best run at epoch 3\n",
      "Train:               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9180    0.9658    0.9413      3338\n",
      "           1     0.7692    0.5689    0.6540       668\n",
      "\n",
      "    accuracy                         0.8997      4006\n",
      "   macro avg     0.8436    0.7674    0.7977      4006\n",
      "weighted avg     0.8932    0.8997    0.8934      4006\n",
      "\n",
      "Dev:               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9226    0.9574    0.9397       846\n",
      "           1     0.7025    0.5556    0.6204       153\n",
      "\n",
      "    accuracy                         0.8959       999\n",
      "   macro avg     0.8125    0.7565    0.7801       999\n",
      "weighted avg     0.8888    0.8959    0.8908       999\n",
      "\n"
     ]
    }
   ],
   "source": [
    "best_run_index = train_state['val_f1s'].index(max(train_state['val_f1s']))\n",
    "print(f'Best run at epoch {best_run_index}')\n",
    "print('Train:',classification_report(\n",
    "    y_pred=(torch.argmax(train_state['train_preds'][best_run_index],dim=1) ).cpu().long().numpy(),\n",
    "    y_true= train_state['train_targets'][best_run_index].cpu().numpy(), \n",
    "    digits=4)\n",
    ")\n",
    "print('Dev:',classification_report(\n",
    "    y_pred=(torch.argmax(train_state['val_preds'][best_run_index],dim=1) ).cpu().long().numpy(),\n",
    "    y_true= train_state['val_targets'][best_run_index].cpu().numpy(), \n",
    "    digits=4)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check if ensembling helps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_preds(indexes, preds):\n",
    "    \"\"\"Sorts the predictions in order, to reverse the effects of shuffle\n",
    "    done by dataloader\"\"\"\n",
    "    indexes = indexes.cpu().numpy().reshape(-1,1)\n",
    "    preds = preds.cpu().numpy()\n",
    "    arr_concat = np.hstack((indexes,preds)) #concat the preds and their indexes\n",
    "    sort_arr = arr_concat[ arr_concat[:,0].argsort()] #sort based on the indexes\n",
    "    sorted_preds = np.delete(sort_arr,0,axis=1)\n",
    "    return sorted_preds\n",
    "\n",
    "def get_optimal_models(train_state, split, reverse=False ):\n",
    "    \"\"\"Naive Ensembling\"\"\"\n",
    "    trgts= sort_preds(train_state[f'{split}_indexes'][-1],train_state[f'{split}_targets'][-1].reshape(-1,1))\n",
    "    total_preds = len(train_state[f'{split}_indexes'])\n",
    "    init = np.zeros(train_state[f'{split}_preds'][-1].shape)\n",
    "    max_f1 = 0\n",
    "    idxes = []\n",
    "    rng = range(0,total_preds)\n",
    "    if reverse:\n",
    "        rng = reversed(rng)\n",
    "    for i in rng:\n",
    "        temp = sort_preds(train_state[f'{split}_indexes'][i],train_state[f'{split}_preds'][i])\n",
    "        temp2 = init+temp\n",
    "        f1 = f1_score(\n",
    "            y_pred=temp2.argmax(axis=1),\n",
    "            y_true= trgts, average ='weighted'\n",
    "        )\n",
    "        if f1 > max_f1:\n",
    "            max_f1 = f1\n",
    "            init = init+temp\n",
    "            idxes.append(i)\n",
    "    print(f'Taking preds from {idxes} | Dev f1:{f1}')\n",
    "    return idxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Taking preds from [7, 6, 5, 3, 2] | Dev f1:0.8969053566642802\n"
     ]
    }
   ],
   "source": [
    "optimal_models= get_optimal_models(train_state,'val', reverse=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_epoc_0_xlmroberta_attn_trac_hin_task_b.pt\r\n",
      "_epoc_1_xlmroberta_attn_trac_hin_task_b.pt\r\n",
      "_epoc_2_xlmroberta_attn_trac_hin_task_b.pt\r\n",
      "_epoc_3_xlmroberta_attn_trac_hin_task_b.pt\r\n",
      "_epoc_4_xlmroberta_attn_trac_hin_task_b.pt\r\n",
      "_epoc_5_xlmroberta_attn_trac_hin_task_b.pt\r\n",
      "_epoc_6_xlmroberta_attn_trac_hin_task_b.pt\r\n",
      "_epoc_7_xlmroberta_attn_trac_hin_task_b.pt\r\n"
     ]
    }
   ],
   "source": [
    "!ls {args.directory}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/home/kaushik.das/OffensEval2020/saved_models/Sun_15_Mar_2020/trac/task_b/xlmroberta_attn/_epoc_0_xlmroberta_attn_trac_hin_task_b.pt',\n",
       " '/home/kaushik.das/OffensEval2020/saved_models/Sun_15_Mar_2020/trac/task_b/xlmroberta_attn/_epoc_1_xlmroberta_attn_trac_hin_task_b.pt',\n",
       " '/home/kaushik.das/OffensEval2020/saved_models/Sun_15_Mar_2020/trac/task_b/xlmroberta_attn/_epoc_2_xlmroberta_attn_trac_hin_task_b.pt',\n",
       " '/home/kaushik.das/OffensEval2020/saved_models/Sun_15_Mar_2020/trac/task_b/xlmroberta_attn/_epoc_3_xlmroberta_attn_trac_hin_task_b.pt',\n",
       " '/home/kaushik.das/OffensEval2020/saved_models/Sun_15_Mar_2020/trac/task_b/xlmroberta_attn/_epoc_4_xlmroberta_attn_trac_hin_task_b.pt',\n",
       " '/home/kaushik.das/OffensEval2020/saved_models/Sun_15_Mar_2020/trac/task_b/xlmroberta_attn/_epoc_5_xlmroberta_attn_trac_hin_task_b.pt',\n",
       " '/home/kaushik.das/OffensEval2020/saved_models/Sun_15_Mar_2020/trac/task_b/xlmroberta_attn/_epoc_6_xlmroberta_attn_trac_hin_task_b.pt',\n",
       " '/home/kaushik.das/OffensEval2020/saved_models/Sun_15_Mar_2020/trac/task_b/xlmroberta_attn/_epoc_7_xlmroberta_attn_trac_hin_task_b.pt']"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_models= [os.path.join(args.directory,i) for i in os.listdir(args.directory)]\n",
    "all_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/home/kaushik.das/OffensEval2020/saved_models/Sun_15_Mar_2020/trac/task_b/xlmroberta_attn/_epoc_7_xlmroberta_attn_trac_hin_task_b.pt',\n",
      " '/home/kaushik.das/OffensEval2020/saved_models/Sun_15_Mar_2020/trac/task_b/xlmroberta_attn/_epoc_6_xlmroberta_attn_trac_hin_task_b.pt',\n",
      " '/home/kaushik.das/OffensEval2020/saved_models/Sun_15_Mar_2020/trac/task_b/xlmroberta_attn/_epoc_5_xlmroberta_attn_trac_hin_task_b.pt',\n",
      " '/home/kaushik.das/OffensEval2020/saved_models/Sun_15_Mar_2020/trac/task_b/xlmroberta_attn/_epoc_3_xlmroberta_attn_trac_hin_task_b.pt',\n",
      " '/home/kaushik.das/OffensEval2020/saved_models/Sun_15_Mar_2020/trac/task_b/xlmroberta_attn/_epoc_2_xlmroberta_attn_trac_hin_task_b.pt']\n"
     ]
    }
   ],
   "source": [
    "selected_models = [all_models[i] for i in optimal_models]\n",
    "pprint.pprint(selected_models)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading test set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set_loc = '/home/kaushik.das/OffensEval2020/data/TRAC/test/trac2_hin_test.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv(test_set_loc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['text'] = test_df['Text'].map(roberta_preproc.add_special_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['split'] = 'test'  #dummy label\n",
    "test_df['label'] = -1  #dummy label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Text</th>\n",
       "      <th>text</th>\n",
       "      <th>split</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C52.17</td>\n",
       "      <td>ko</td>\n",
       "      <td>&lt;s&gt; ko &lt;/s&gt;</td>\n",
       "      <td>test</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C52.39</td>\n",
       "      <td>ladkiyon video</td>\n",
       "      <td>&lt;s&gt; ladkiyon video &lt;/s&gt;</td>\n",
       "      <td>test</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C52.73</td>\n",
       "      <td>ki video gahrep</td>\n",
       "      <td>&lt;s&gt; ki video gahrep &lt;/s&gt;</td>\n",
       "      <td>test</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C60.3</td>\n",
       "      <td>o sadharon video bhai</td>\n",
       "      <td>&lt;s&gt; o sadharon video bhai &lt;/s&gt;</td>\n",
       "      <td>test</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C60.43</td>\n",
       "      <td>ba bhai kyea bola tum moza aaa giea 😌😌😌😂😂😂</td>\n",
       "      <td>&lt;s&gt; ba bhai kyea bola tum moza aaa giea 😌😌😌😂😂😂...</td>\n",
       "      <td>test</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1195</th>\n",
       "      <td>C8.5029</td>\n",
       "      <td>aree bhenchod chup ho lodu aurt</td>\n",
       "      <td>&lt;s&gt; aree bhenchod chup ho lodu aurt &lt;/s&gt;</td>\n",
       "      <td>test</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1196</th>\n",
       "      <td>C8.5037</td>\n",
       "      <td>abe saali bharwe itni gaand kyun fati hui he t...</td>\n",
       "      <td>&lt;s&gt; abe saali bharwe itni gaand kyun fati hui ...</td>\n",
       "      <td>test</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1197</th>\n",
       "      <td>C8.5046</td>\n",
       "      <td>chachi ji... usne ek mara lekin lerki ne jo is...</td>\n",
       "      <td>&lt;s&gt; chachi ji... usne ek mara lekin lerki ne j...</td>\n",
       "      <td>test</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1198</th>\n",
       "      <td>C8.5047</td>\n",
       "      <td>sun oye bhenkilodi itnaa maarunga saali tod du...</td>\n",
       "      <td>&lt;s&gt; sun oye bhenkilodi itnaa maarunga saali to...</td>\n",
       "      <td>test</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1199</th>\n",
       "      <td>C8.5076</td>\n",
       "      <td>arey gaand m aag lg gyi bhnchod 😂😂😂 so called ...</td>\n",
       "      <td>&lt;s&gt; arey gaand m aag lg gyi bhnchod 😂😂😂 so cal...</td>\n",
       "      <td>test</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1200 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           ID                                               Text  \\\n",
       "0      C52.17                                                 ko   \n",
       "1      C52.39                                     ladkiyon video   \n",
       "2      C52.73                                    ki video gahrep   \n",
       "3       C60.3                              o sadharon video bhai   \n",
       "4      C60.43         ba bhai kyea bola tum moza aaa giea 😌😌😌😂😂😂   \n",
       "...       ...                                                ...   \n",
       "1195  C8.5029                    aree bhenchod chup ho lodu aurt   \n",
       "1196  C8.5037  abe saali bharwe itni gaand kyun fati hui he t...   \n",
       "1197  C8.5046  chachi ji... usne ek mara lekin lerki ne jo is...   \n",
       "1198  C8.5047  sun oye bhenkilodi itnaa maarunga saali tod du...   \n",
       "1199  C8.5076  arey gaand m aag lg gyi bhnchod 😂😂😂 so called ...   \n",
       "\n",
       "                                                   text split  label  \n",
       "0                                           <s> ko </s>  test     -1  \n",
       "1                               <s> ladkiyon video </s>  test     -1  \n",
       "2                              <s> ki video gahrep </s>  test     -1  \n",
       "3                        <s> o sadharon video bhai </s>  test     -1  \n",
       "4     <s> ba bhai kyea bola tum moza aaa giea 😌😌😌😂😂😂...  test     -1  \n",
       "...                                                 ...   ...    ...  \n",
       "1195           <s> aree bhenchod chup ho lodu aurt </s>  test     -1  \n",
       "1196  <s> abe saali bharwe itni gaand kyun fati hui ...  test     -1  \n",
       "1197  <s> chachi ji... usne ek mara lekin lerki ne j...  test     -1  \n",
       "1198  <s> sun oye bhenkilodi itnaa maarunga saali to...  test     -1  \n",
       "1199  <s> arey gaand m aag lg gyi bhnchod 😂😂😂 so cal...  test     -1  \n",
       "\n",
       "[1200 rows x 5 columns]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = TracDataset(\n",
    "    data_df = test_df,\n",
    "    tokenizer = xlmroberta_tokenizer,\n",
    "    max_seq_length = dataset._max_seq_length\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset.set_split('test')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "test    1200\n",
       "Name: split, dtype: int64"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset._target_df.split.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d74ea56881f4275b5e52ba300c548a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='split=train ', max=37.0, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "930c1cb872b04654ace3574993d2afe0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=5.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "test_state = general_utils.make_train_state() \n",
    "test_dataset.set_split('test')\n",
    "eval_bar = notebook.tqdm(\n",
    "    desc = 'split=train ',\n",
    "    total=test_dataset.get_num_batches(args.batch_size),\n",
    "    position=0,\n",
    "    leave=True,\n",
    ")\n",
    "model.eval()\n",
    "for m in notebook.tqdm(selected_models, total=len(selected_models)):\n",
    "    eval_bar.reset(\n",
    "        total=test_dataset.get_num_batches(args.batch_size),\n",
    "    )\n",
    "    model.load_state_dict(torch.load(m)['model'])\n",
    "    batch_generator = generate_batches(\n",
    "        dataset= test_dataset, batch_size= args.batch_size, shuffle=False,\n",
    "        device = args.device, drop_last=False,\n",
    "        pinned_memory = True, n_workers = 1, \n",
    "    )\n",
    "    with torch.no_grad():\n",
    "        for batch_index, batch_dict in enumerate(batch_generator):\n",
    "            y_pred = model(\n",
    "                input_ids = batch_dict['x_data'],\n",
    "                attention_mask =  batch_dict['x_attn_mask'],\n",
    "            )\n",
    "            y_pred = y_pred.view(-1, len(set(dataset.data_df.label)))\n",
    "            \n",
    "            y_pred = y_pred.detach()\n",
    "            \n",
    "            batch_dict['y_target'] = batch_dict['y_target'].cpu()\n",
    "            test_state['batch_preds'].append(y_pred.cpu())\n",
    "            test_state['batch_targets'].append(batch_dict['y_target'].cpu())\n",
    "            test_state['batch_indexes'].append(batch_dict['x_index'].cpu())\n",
    "            eval_bar.update()\n",
    "\n",
    "    test_state['val_preds'].append(\n",
    "        torch.cat(test_state['batch_preds']).cpu()\n",
    "    )\n",
    "    test_state['val_targets'].append(\n",
    "        torch.cat(test_state['batch_targets']).cpu()\n",
    "    )\n",
    "    test_state['val_indexes'].append(\n",
    "        torch.cat(test_state['batch_indexes']).cpu()\n",
    "    )\n",
    "    \n",
    "    test_state['batch_preds'] = []\n",
    "    test_state['batch_targets'] = []\n",
    "    test_state['batch_indexes'] = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(test_state['val_preds']) == len(optimal_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[torch.Size([1200, 2]),\n",
       " torch.Size([1200, 2]),\n",
       " torch.Size([1200, 2]),\n",
       " torch.Size([1200, 2]),\n",
       " torch.Size([1200, 2])]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[test_state['val_preds'][i].shape for i in range(len(optimal_models))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble = torch.zeros_like(test_state['val_preds'][-1])\n",
    "for i in test_state['val_preds']:\n",
    "    ensemble += i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_preds = torch.argmax(ensemble, dim=1).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0: 664, 1: 536})"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collections.Counter(test_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'NGEN': 664, 'GEN': 536})"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# task_b_label_dict = {'NGEN':0, 'GEN':1} #ref Reading TRAC2020 data... ipynb\n",
    "int_to_label = {0:'NGEN', 1:'GEN'}\n",
    "pred_labels = [int_to_label[i] for i in test_preds]\n",
    "collections.Counter(pred_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df = pd.DataFrame( data= {'id':test_df.ID, 'label':pred_labels})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_analysis_df = pd.DataFrame( data= {'id':test_df.ID, 'text':test_df.Text ,'label':pred_labels})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C52.17</td>\n",
       "      <td>NGEN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C52.39</td>\n",
       "      <td>NGEN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C52.73</td>\n",
       "      <td>NGEN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C60.3</td>\n",
       "      <td>NGEN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C60.43</td>\n",
       "      <td>NGEN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1195</th>\n",
       "      <td>C8.5029</td>\n",
       "      <td>GEN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1196</th>\n",
       "      <td>C8.5037</td>\n",
       "      <td>GEN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1197</th>\n",
       "      <td>C8.5046</td>\n",
       "      <td>GEN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1198</th>\n",
       "      <td>C8.5047</td>\n",
       "      <td>GEN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1199</th>\n",
       "      <td>C8.5076</td>\n",
       "      <td>GEN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1200 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           id label\n",
       "0      C52.17  NGEN\n",
       "1      C52.39  NGEN\n",
       "2      C52.73  NGEN\n",
       "3       C60.3  NGEN\n",
       "4      C60.43  NGEN\n",
       "...       ...   ...\n",
       "1195  C8.5029   GEN\n",
       "1196  C8.5037   GEN\n",
       "1197  C8.5046   GEN\n",
       "1198  C8.5047   GEN\n",
       "1199  C8.5076   GEN\n",
       "\n",
       "[1200 rows x 2 columns]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C52.17</td>\n",
       "      <td>ko</td>\n",
       "      <td>NGEN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C52.39</td>\n",
       "      <td>ladkiyon video</td>\n",
       "      <td>NGEN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C52.73</td>\n",
       "      <td>ki video gahrep</td>\n",
       "      <td>NGEN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C60.3</td>\n",
       "      <td>o sadharon video bhai</td>\n",
       "      <td>NGEN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C60.43</td>\n",
       "      <td>ba bhai kyea bola tum moza aaa giea 😌😌😌😂😂😂</td>\n",
       "      <td>NGEN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1195</th>\n",
       "      <td>C8.5029</td>\n",
       "      <td>aree bhenchod chup ho lodu aurt</td>\n",
       "      <td>GEN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1196</th>\n",
       "      <td>C8.5037</td>\n",
       "      <td>abe saali bharwe itni gaand kyun fati hui he t...</td>\n",
       "      <td>GEN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1197</th>\n",
       "      <td>C8.5046</td>\n",
       "      <td>chachi ji... usne ek mara lekin lerki ne jo is...</td>\n",
       "      <td>GEN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1198</th>\n",
       "      <td>C8.5047</td>\n",
       "      <td>sun oye bhenkilodi itnaa maarunga saali tod du...</td>\n",
       "      <td>GEN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1199</th>\n",
       "      <td>C8.5076</td>\n",
       "      <td>arey gaand m aag lg gyi bhnchod 😂😂😂 so called ...</td>\n",
       "      <td>GEN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1200 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           id                                               text label\n",
       "0      C52.17                                                 ko  NGEN\n",
       "1      C52.39                                     ladkiyon video  NGEN\n",
       "2      C52.73                                    ki video gahrep  NGEN\n",
       "3       C60.3                              o sadharon video bhai  NGEN\n",
       "4      C60.43         ba bhai kyea bola tum moza aaa giea 😌😌😌😂😂😂  NGEN\n",
       "...       ...                                                ...   ...\n",
       "1195  C8.5029                    aree bhenchod chup ho lodu aurt   GEN\n",
       "1196  C8.5037  abe saali bharwe itni gaand kyun fati hui he t...   GEN\n",
       "1197  C8.5046  chachi ji... usne ek mara lekin lerki ne jo is...   GEN\n",
       "1198  C8.5047  sun oye bhenkilodi itnaa maarunga saali tod du...   GEN\n",
       "1199  C8.5076  arey gaand m aag lg gyi bhnchod 😂😂😂 so called ...   GEN\n",
       "\n",
       "[1200 rows x 3 columns]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_analysis_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir hindi_runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df.to_csv('./hindi_runs/hindi_task_b_preds.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_analysis_df.to_csv('./hindi_runs/hindi_task_b_preds_analysis.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hindi_task_b_preds.csv\thindi_task_b_preds_analysis.csv\r\n"
     ]
    }
   ],
   "source": [
    "!ls hindi_runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id,label\r\n",
      "C52.17,NGEN\r\n",
      "C52.39,NGEN\r\n",
      "C52.73,NGEN\r\n",
      "C60.3,NGEN\r\n",
      "C60.43,NGEN\r\n",
      "C60.72,NGEN\r\n",
      "C60.102,NGEN\r\n",
      "C60.118,NGEN\r\n",
      "C60.139,NGEN\r\n"
     ]
    }
   ],
   "source": [
    "!head  ./hindi_runs/hindi_task_a_preds.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                 text  \\\n",
      "157  bc first time kisi ko ladko k baare me sochta dekh rha hu, wrna sc st, girls\\nchild aur girls se uper utha hi nhi kbhi kuch.  \\nappreciate the work 👍                              \n",
      "473  yeah dislikke vali vohi ldkia h jinka bhanda phoot gya😂                                                                                                                            \n",
      "101  sabse jyda india me rape hota hai kyu?...kyunki sachai dabaai jati hai\\n...sayad 100 mese 80 case me aap jante ho...fir bhi innocent aadmi ki izzat ki\\ndachiya ud jati hai.....   \n",
      "445  @silpisikha chetia it's not about some times dear wake up 76 % percent rape\\ncase sirf badle k liye lagati hai larkiya                                                             \n",
      "436  log dislike bhi krte hain ese contact waahhh                                                                                                                                       \n",
      "\n",
      "    label  \n",
      "157  GEN   \n",
      "473  NGEN  \n",
      "101  NGEN  \n",
      "445  NGEN  \n",
      "436  NGEN  \n"
     ]
    }
   ],
   "source": [
    "with pd.option_context('display.max_colwidth', -1): \n",
    "    print(pred_analysis_df[['text','label']].sample(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
